import streamlit as st
import pandas as pd
import numpy as np
import pickle
import get_image_url as get_img


import cv2
import requests
import io




from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.applications.mobilenet import MobileNet

from tqdm import tqdm

from sklearn.svm import LinearSVC
import pickle

from streamlit_custom_notification_box import custom_notification_box

from PIL import Image

import time

styles = {'material-icons':{'color': 'green'},
          'text-icon-link-close-container': {'box-shadow': '#3896de 0px 10px'},
          'notification-text': {'':''},
          'close-button':{'':''},
          'link':{'':''}}


def encode_img_to_vec(image_data):
  # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà OpenCV ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ
  image_array = np.asarray(bytearray(image_data), dtype=np.uint8)
  image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
  resized_image = cv2.resize(image, (300, 300))
  # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• VGG16 
  model = VGG16(weights='imagenet', include_top=False)

  # ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• VGG16
  preprocessed_image = preprocess_input(resized_image)
  expanded_image = np.expand_dims(preprocessed_image, axis=0)

  # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ encode ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå
  feature_vector = model.predict(expanded_image)

  # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå 1 ‡∏°‡∏¥‡∏ï‡∏¥
  encoded_vector = feature_vector.flatten() 
  return encoded_vector

def encode(url):
  # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å URL
  response = requests.get(url)
  image_data = response.content
  return encode_img_to_vec(image_data)

def featextraction(queryList ):
  dataList = []
  for j in range(len(queryList)):
    query = queryList[j]
    imgList = get_img.get_image_urls(query)
    featList = []
    for i in range(len(imgList)):
      try:
        img = imgList[i]
        cvo = encode(img)
        print("image ",i," success")
        featList.append(cvo)
      except:
        print("image ",i," Not success")
        pass
    dat = pd.DataFrame(data=[featList]).T
    dat['label'] = query
    dat.columns = ['feature','label']
    dataList.append(dat)  
  return pd.concat(dataList)

def trainmodel(res):
  print('start train')
  clf = LinearSVC()
  clf.fit(np.vstack(res['feature'].values),res['label'].values)
  path = "./model/vectorizer.pickle"
  with open(path, 'wb') as file:
    pickle.dump(clf, file)
    print('success')
  # return clf

def prediction_from_URL(imgurl,clf):
  featList = []
  cvo = encode(imgurl)
  featList.append(cvo)
  dat = pd.DataFrame(data=[featList]).T
  return clf.predict(np.vstack(dat[0].values))[0]
def prediction_from_img(image_data,clf):
  featList = []
  cvo = encode_img_to_vec(image_data)
  featList.append(cvo)
  dat = pd.DataFrame(data=[featList]).T
  return clf.predict(np.vstack(dat[0].values))[0]

@st.cache_data
def load_data():
    return pd.DataFrame(
        {
            "‡∏´‡∏°‡∏≤üê∂": ["‡∏ä‡∏¥‡∏™‡∏∏","‡πÇ‡∏Å‡∏•‡πÄ‡∏î‡πâ‡∏ô‡∏ó‡πå ‡∏£‡∏µ‡∏ó‡∏£‡∏µ‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå","‡∏ö‡∏µ‡πÄ‡∏Å‡∏¥‡πâ‡∏•","‡∏ä‡∏¥‡∏ß‡∏≤‡∏ß‡πà‡∏≤" , "‡πÄ‡∏ü‡∏£‡∏ô‡∏ä‡πå‡∏ö‡∏π‡∏•‡∏î‡πä‡∏≠‡∏Å" , "‡πÑ‡∏ã‡∏ö‡∏µ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏Æ‡∏±‡∏™‡∏Å‡∏µ‡πâ"],
            "‡πÅ‡∏°‡∏ßüê±": ["‡∏™‡∏Å‡πä‡∏≠‡∏ï‡∏ï‡∏¥‡∏ä ‡πÇ‡∏ü‡∏•‡∏î‡πå", "‡πÄ‡∏≠‡πá‡∏Å‡πÇ‡∏ã‡∏ï‡∏¥‡∏Å", "‡∏≠‡πÄ‡∏°‡∏£‡∏¥‡∏Å‡∏±‡∏ô ‡∏ä‡∏≠‡∏£‡πå‡∏ï‡πÅ‡∏Æ‡∏£‡πå", "‡∏ß‡∏¥‡πÄ‡∏ä‡∏µ‡∏¢‡∏£‡∏°‡∏≤‡∏®" ,"‡∏Ç‡∏≤‡∏ß‡∏°‡∏ì‡∏µ","‡∏™‡∏µ‡∏™‡∏ß‡∏≤‡∏î"]
        }
    )
class main :
  def main():
    print("server start")

    st.title("Image classification")
    st.subheader("üê±‡∏Ñ‡∏±‡∏î‡πÅ‡∏¢‡∏Å‡∏™‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå ‡∏´‡∏°‡∏≤&‡πÅ‡∏°‡∏ß ‡∏¢‡∏≠‡∏î‡∏Æ‡∏¥‡∏ï‡πÉ‡∏ô‡πÑ‡∏ó‡∏¢üê∂")
    mp4_file = "https://ik.imagekit.io/seproject/converted_video.mp4?updatedAt=1686420832938"

    if mp4_file is not None:
      # ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
      st.video(mp4_file,format='GIF', start_time=0)

    st.write("üì£‡∏™‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå ‡∏´‡∏°‡∏≤&‡πÅ‡∏°‡∏ß ‡∏ó‡∏µ‡πà AI ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÑ‡∏î‡πâ")
    df = load_data()
    st.dataframe(df )
    st.subheader("‚ö†Ô∏è‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏™‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ copy image address url ‡∏´‡∏£‡∏∑‡∏≠ ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£ upload file ‡∏Å‡πá‡πÑ‡∏î‡πâ")
    url = st.text_input('üìåURL ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≤‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö (‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Image address ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞ ‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢.jpg ‡∏´‡∏£‡∏∑‡∏≠ .png)','Image address url( .jpg or .png )')
    model = pickle.load(open('./model/vectorizer.pickle', 'rb'))
    if st.button('predict'):
      with st.spinner('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û'):
         time.sleep(2)
      pr = prediction_from_URL(url,model)
      print(pr)
      st.image(url, caption='‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î')
      st.subheader("‚úÖ ‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏∏ : "+str(pr))
      st.write("‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡∏Å AI ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏∂‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô")
    uploaded_file = st.file_uploader('‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û', type=['jpg', 'png', 'jpeg'])
    if uploaded_file is not None:
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
        image = Image.open(uploaded_file)
        # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô Streamlit
        with st.spinner('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û'):
         time.sleep(1.5)
        st.image(image, caption='‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î')
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô bytearray
        byte_stream = io.BytesIO()
        image.save(byte_stream, format='JPEG')
        image_data = byte_stream.getvalue()
        pr = prediction_from_img(image_data,model)
        print(pr)
        st.subheader("‚úÖ ‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏∏ : "+str(pr))
        st.write("‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡∏Å AI ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏∂‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô")
      
    # st.subheader("‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏∞‡πÄ‡∏ó‡∏£‡∏ô AI")
    # size_of_prediction = st.slider('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô AI (‡∏¢‡∏¥‡πà‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô AI ‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏™‡πà‡∏á‡∏ú‡∏•‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô AI ‡∏Å‡πá‡∏à‡∏∞‡∏ô‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô) ', 2, 5, 2)
    # data_list=[] 
    # if size_of_prediction == 2:
    #       data1 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 1', '‡∏™‡∏∏‡∏ô‡∏±‡∏Ç')
    #       data2 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 2', '‡πÅ‡∏°‡∏ß')
    #       data_list.append(data1)
    #       data_list.append(data2)
    # elif size_of_prediction == 3:
    #       data1 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 1', '')
    #       data2 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 2', '')
    #       data3 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 3', '')
    #       data_list.append(data1)
    #       data_list.append(data2)
    #       data_list.append(data3)
    # elif size_of_prediction == 4:
    #       data1 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 1', '')
    #       data2 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 2', '')
    #       data3 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 3', '')
    #       data4 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 4', '')
    #       data_list.append(data1)
    #       data_list.append(data2)
    #       data_list.append(data3)
    #       data_list.append(data4)
    # elif size_of_prediction == 5:
    #       data1 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 1', '')
    #       data2 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 2', '')
    #       data3 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 3', '')
    #       data4 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 4', '')
    #       data5 = st.text_input('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà 5', '')
    #       data_list.append(data1)
    #       data_list.append(data2)
    #       data_list.append(data3)
    #       data_list.append(data4)
    #       data_list.append(data5)
    
    # feat = None 
    # if st.button('train model'):
    #     with st.spinner('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô AI ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô ‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà '):
    #       feat =featextraction(data_list )
    #       model =trainmodel(feat)
    #       custom_notification_box(icon='done', textDisplay='Train model ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à', externalLink='', url='#', styles=styles, key="foo")
    # if st.button('test model'):
    #     st.session_state["page"] = "‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏≠‡∏á"
    # if st.button("‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å"):
    #       st.session_state["page"] = "‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å"
  # Specify the number of columns

  def predict_page():
    if st.button('back'):
      st.session_state["page"] = "‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å"
    st.title("Image classification")
    # st.subheader("‡∏ó‡∏î‡∏™‡∏≠‡∏ö AI ")
    # st.write("‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ copy image address url ‡∏´‡∏£‡∏∑‡∏≠ ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£ upload file ‡∏Å‡πá‡πÑ‡∏î‡πâ")
    # url = st.text_input('URL ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≤‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö (‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Image address ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞ ‡∏ï‡πâ‡∏≠‡∏á‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢.jpg ‡∏´‡∏£‡∏∑‡∏≠ .png)','Image address url( .jpg or .png )')
    # model = pickle.load(open('./model/vectorizer.pickle', 'rb'))
    # if st.button('predict'):
    #   pr = prediction_from_URL(url,model)
    #   print(pr)
    #   st.image(url, caption='‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î')
    #   st.subheader("‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ : "+str(pr))
    # uploaded_file = st.file_uploader('‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û', type=['jpg', 'png', 'jpeg'])
    # if uploaded_file is not None:
    #     # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
    #     image = Image.open(uploaded_file)
    #     # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô Streamlit
    #     st.image(image, caption='‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î')
    #     # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô bytearray
    #     byte_stream = io.BytesIO()
    #     image.save(byte_stream, format='JPEG')
    #     image_data = byte_stream.getvalue()
    #     pr = prediction_from_img(image_data,model)
    #     print(pr)
    #     st.subheader("‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ : "+str(pr))

  if "page" not in st.session_state:
      st.session_state["page"] = "‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å"

  if st.session_state["page"] == "‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏≠‡∏á":
      predict_page()
  else:
      main()


if __name__ == "__main__":
    main()

